
# Word2vec algorithm from scratch

The Word2vec algorithm uses a neural network model to learn word associations from a large corpus of text.

This repository contains a python notebook explaining the theory behind and the code implementation of word2vec
## Badges

[![MIT License](https://img.shields.io/apm/l/atomic-design-ui.svg?)](https://github.com/tterb/atomic-design-ui/blob/master/LICENSEs)



## Dependencies

To run this project, you need the following python libraries

`jupyter`

`matplotlib`

`numpy`

`scikit-learn`

## Dataset
**Stanford Sentiment Treebank (SST)** dataset is used to train
word vectors.To fetch the datasets run the datasets.sh file found utils directory
## License

[MIT](https://choosealicense.com/licenses/mit/)


## Reference

1. [Stanford CS224n lecture note](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf)
2. [NLPâ€™s word2vec: Negative Sampling Explained](https://www.baeldung.com/cs/nlps-word2vec-negative-sampling#:~:text=In%20a%20nutshell%2C%20by%20defining,they%20occur%20in%20different%20contexts.)
3. [Word2vec Wikioedia](https://en.wikipedia.org/wiki/Word2vec)